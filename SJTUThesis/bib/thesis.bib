%# -*- coding: utf-8-unix -*-

@article{Kurnia2001,
abstract = {This report describes and evaluates the implementation and applicability of an automatic programming assignment grading system we named the online judge. We compared this with the manual grading system that is currently being used and showed that the automatic grading system, when implemented carefully, is more convenient, fairer, and more secure than the former. We have successfully tested the system on two courses. However, further studies need to be conducted to improve the effectiveness of learning through this system. {\#}},
author = {Kurnia, Andy and Lim, Andrew and Cheang, Brenda},
file = {:Users/abcdabcd987/Documents/Mendeley Desktop/Online Judge - Kurnia, Lim, Cheang - 2001.pdf:pdf},
journal = {Computers {\&} Education},
keywords = {Automatic grading system,Online judge,Programming assignments},
mendeley-groups = {Undergraduate Thesis},
number = {36},
pages = {299--315},
title = {{Online Judge}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.18.4626{\&}rep=rep1{\&}type=pdf},
year = {2001}
}


@article{Li2005,
abstract = {POJ ( Peking University Online Judge ) system is aiming at training the ACM/ICPC ( Association of Comuting Machinery/Intenational Collegiate Programming Contest) PKU team members. The system functions include user management, task library, realtime submission and judgement, discussion board, email system. It can he widely used in programming related courses in helping with the homework remarking and online examina-tion. In Peking University, POJ has been integrated in some courses such as 《Introduction to Computing》, 《C + + programming》, 《Data Structure and Algorithms》 and 《Problem solving and Programming》. Through POJ, the students may submit their homework at anytime and get prompt remark to their submisions. Professors can al-so watch the students behaviours on POJ and find out the most common problems with the students in learning. Taking exams on POJ makes the students try their best to improve their online programming techniques in stead of just remembering all the things. Meanwhile it is easier to find out similar programs so that less students copy their homework from others. POJ as a smart tool is a good helper in teaching programming.},
author = {Li, Wen-xin and Guo, Wei},
file = {:Users/abcdabcd987/Documents/Mendeley Desktop/Peking University Oneline Judge and Its Applications - Li, Guo - 2005.pdf:pdf},
journal = {Journal of Changchun Post and Telecommunication Institute},
mendeley-groups = {Undergraduate Thesis},
title = {{Peking University Oneline Judge and Its Applications}},
url = {http://en.cnki.com.cn/Article{\_}en/CJFDTOTAL-CCYD2005S2046.htm},
volume = {S2},
year = {2005}
}


@article{Simard2017,
abstract = {The current processes for building machine learning systems require practitioners with deep knowledge of machine learning. This significantly limits the number of machine learning systems that can be created and has led to a mismatch between the demand for machine learning systems and the ability for organizations to build them. We believe that in order to meet this growing demand for machine learning systems we must significantly increase the number of individuals that can teach machines. We postulate that we can achieve this goal by making the process of teaching machines easy, fast and above all, universally accessible. While machine learning focuses on creating new algorithms and improving the accuracy of "learners", the machine teaching discipline focuses on the efficacy of the "teachers". Machine teaching as a discipline is a paradigm shift that follows and extends principles of software engineering and programming languages. We put a strong emphasis on the teacher and the teacher's interaction with data, as well as crucial components such as techniques and design principles of interaction and visualization. In this paper, we present our position regarding the discipline of machine teaching and articulate fundamental machine teaching principles. We also describe how, by decoupling knowledge about machine learning algorithms from the process of teaching, we can accelerate innovation and empower millions of new uses for machine learning models.},
archivePrefix = {arXiv},
arxivId = {1707.06742},
author = {Simard, Patrice Y. and Amershi, Saleema and Chickering, David M. and Pelton, Alicia Edelman and Ghorashi, Soroush and Meek, Christopher and Ramos, Gonzalo and Suh, Jina and Verwey, Johan and Wang, Mo and Wernsing, John},
eprint = {1707.06742},
file = {:Users/abcdabcd987/Documents/Mendeley Desktop/Machine Teaching A New Paradigm for Building Machine Learning Systems - Simard et al. - 2017.pdf:pdf},
mendeley-groups = {Undergraduate Thesis},
title = {{Machine Teaching: A New Paradigm for Building Machine Learning Systems}},
url = {http://arxiv.org/abs/1707.06742},
year = {2017}
}

@article{Zhu2018,
abstract = {In this paper we try to organize machine teaching as a coherent set of ideas. Each idea is presented as varying along a dimension. The collection of dimensions then form the problem space of machine teaching, such that existing teaching problems can be characterized in this space. We hope this organization allows us to gain deeper understanding of individual teaching problems, discover connections among them, and identify gaps in the field.},
archivePrefix = {arXiv},
arxivId = {1801.05927},
author = {Zhu, Xiaojin and Singla, Adish and Zilles, Sandra and Rafferty, Anna N.},
eprint = {1801.05927},
file = {:Users/abcdabcd987/Documents/Mendeley Desktop/An Overview of Machine Teaching - Zhu et al. - 2018.pdf:pdf},
mendeley-groups = {Undergraduate Thesis},
title = {{An Overview of Machine Teaching}},
year = {2018}
}

@article{Suh2016,
abstract = {Mixed-initiative classifier training, where the hu-man teacher can choose which items to label or to label items chosen by the computer, has enjoyed empirical success but without a rigor-ous statistical learning theoretical justification. We analyze the label complexity of a simple mixed-initiative training mechanism using teach-ing dimension and active learning. We show that mixed-initiative training is advantageous com-pared to either computer-initiated (represented by active learning) or human-initiated classifier training. The advantage exists across all human teaching abilities, from optimal to completely unhelpful teachers. We further improve classifier training by educating the human teachers. This is done by showing, or explaining, optimal teaching sets to the human teachers. We conduct Mechani-cal Turk human experiments on two stylistic clas-sifier training tasks to illustrate our approach.},
author = {Suh, Jina and Com, Samershi Microsoft},
file = {:Users/abcdabcd987/Documents/Mendeley Desktop/The Label Complexity of Mixed-Initiative Classifier Training - Suh, Com - 2016.pdf:pdf},
isbn = {9781510829008},
journal = {Icml},
mendeley-groups = {Undergraduate Thesis},
title = {{The Label Complexity of Mixed-Initiative Classifier Training}},
year = {2016}
}

@article{Alfeld2016,
abstract = {Forecasting models play a key role in money-making ventures in many different markets. Such models are of-ten trained on data from various sources, some of which may be untrustworthy. An actor in a given market may be incentivised to drive predictions in a certain direction to their own benefit. Prior analyses of intelligent adver-saries in a machine-learning context have focused on re-gression and classification. In this paper we address the non-iid setting of time series forecasting. We consider a forecaster, Bob, using a fixed, known model and a re-cursive forecasting method. An adversary, Alice, aims to pull Bob's forecasts toward her desired target series, and may exercise limited influence on the initial val-ues fed into Bob's model. We consider the class of lin-ear autoregressive models, and a flexible framework of encoding Alice's desires and constraints. We describe a method of calculating Alice's optimal attack that is computationally tractable, and empirically demonstrate its effectiveness compared to random and greedy base-lines on synthetic and real-world time series data. We conclude by discussing defensive strategies in the face of Alice-like adversaries.},
author = {Alfeld, Scott and Zhu, Xiaojin and Barford, Paul},
file = {:Users/abcdabcd987/Documents/Mendeley Desktop/Data Poisoning Attacks against Autoregressive Models - Alfeld, Zhu, Barford - 2016.pdf:pdf},
isbn = {9781577357605},
journal = {Aaai},
keywords = {Technical Papers: Machine Learning Methods},
mendeley-groups = {Undergraduate Thesis},
title = {{Data Poisoning Attacks against Autoregressive Models}},
year = {2016}
}

@article{Mei2015,
abstract = {We investigate a problem at the intersection of machine learning and security: training-set attacks on machine learners. In such attacks an attacker contaminates the training data so that a specific learning algorithm would produce a model profitable to the attacker. Understand-ing training-set attacks is important as more intelli-gent agents (e.g. spam filters and robots) are equipped with learning capability and can potentially be hacked via data they receive from the environment. This pa-per identifies the optimal training-set attack on a broad family of machine learners. First we show that opti-mal training-set attack can be formulated as a bilevel optimization problem. Then we show that for machine learners with certain Karush-Kuhn-Tucker conditions we can solve the bilevel problem efficiently using gra-dient methods on an implicit function. As examples, we demonstrate optimal training-set attacks on Support Vector Machines, logistic regression, and linear regres-sion with extensive experiments. Finally, we discuss po-tential defenses against such attacks.},
author = {Mei, Shike and Zhu, Xiaojin},
file = {:Users/abcdabcd987/Documents/Mendeley Desktop/Using Machine Teaching to Identify Optimal Training-Set Attacks on Machine Learners - Mei, Zhu - 2015.pdf:pdf},
isbn = {9781577357025},
journal = {Twenty-Ninth AAAI Conference on Artificial Intelligence},
keywords = {Novel Machine Learning Algorithms Track},
mendeley-groups = {Undergraduate Thesis},
pages = {2871--2877},
title = {{Using Machine Teaching to Identify Optimal Training-Set Attacks on Machine Learners}},
url = {http://pages.cs.wisc.edu/{~}jerryzhu/pub/Mei2015Machine.pdf},
year = {2015}
}

@article{Whitehill2017,
author = {Whitehill, Jacob and Movellan, Javier},
doi = {10.1109/TLT.2017.2692761},
file = {:Users/abcdabcd987/Documents/Mendeley Desktop/Approximately Optimal Teaching of Approximately Optimal Learners - Whitehill, Movellan - 2017.pdf:pdf},
issn = {1939-1382},
journal = {IEEE Transactions on Learning Technologies},
mendeley-groups = {Undergraduate Thesis},
number = {9},
pages = {1--1},
title = {{Approximately Optimal Teaching of Approximately Optimal Learners}},
url = {http://ieeexplore.ieee.org/document/7895197/},
volume = {13},
year = {2017}
}

@article{Patil2014,
abstract = {Basic decisions, such as judging a person as a friend or foe, involve categorizing novel stimuli. Recent work finds that people's category judgments are guided by a small set of examples that are retrieved from memory at decision time. This limited and stochastic retrieval places limits on human performance for proba-bilistic classification decisions. In light of this capacity limitation, recent work finds that idealizing training items, such that the saliency of ambiguous cases is reduced, improves human performance on novel test items. One shortcoming of previous work in idealization is that category distributions were idealized in an ad hoc or heuristic fashion. In this contribution, we take a first principles approach to constructing idealized training sets. We apply a machine teaching procedure to a cognitive model that is either limited capacity (as humans are) or unlimited capacity (as most machine learning systems are). As predicted, we find that the machine teacher recommends idealized training sets. We also find that human learners perform best when training recommendations from the machine teacher are based on a limited-capacity model. As predicted, to the extent that the learning model used by the machine teacher conforms to the true nature of human learners, the recommendations of the machine teacher prove effective. Our results provide a normative basis (given capacity constraints) for idealization procedures and offer a novel selection procedure for models of human learning.},
author = {Patil, Kaustubh Raosaheb and Love, Bradley C},
file = {:Users/abcdabcd987/Documents/Mendeley Desktop/Optimal Teaching for Limited-Capacity Human Learners - Patil, Love - 2014.pdf:pdf},
issn = {10495258},
journal = {Nips},
mendeley-groups = {Undergraduate Thesis},
pages = {1--9},
title = {{Optimal Teaching for Limited-Capacity Human Learners}},
year = {2014}
}

