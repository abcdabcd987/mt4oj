%# -*- coding: utf-8-unix -*-
% !TEX program = xelatex
% !TEX root = ../thesis.tex

\chapter{Related Works}
\label{chap:related}

\section{Machine Teaching}

    Machine teaching is not a brand new research topic.
    There has been a long history of related work dated back to 1990s.
    Recently, machine teaching started to draw researchers' attention again.
    Xiaojin Zhu's paper in Socratic dialogue style \cite{Zhu2015} stimulates critical thinking of
    what machine learning is and how it might help machines and humans.
    The paper also proposed several open problems and calls on study of the research community.
    The longer version \cite{Zhu2018} of this paper explains things in more detail.

    As in any field, theory is the pillar of machine teaching.
    Although finding the optimal training set is in general hard,
    several works provide solutions to specific learners.
    \textcite{zhu2013machine} presents an approximate algorithm for finding the optimal teaching set
    for Bayesian learners which employ conjugate exponential family models.
    \textcite{xuezhou_zhang_optimal_2016} studies online learners, specially the perceptron.
    \textcite{liu2016teaching} presents the first known teaching dimension for ridge regression,
    support vector machines, and logistic regression.
    \textcite{zhu2017no} studies an interesting setting similar to the real-world classroom
    where the teacher must use the same training set to teach multiple learners.
    \textcite{ma2018teacher} proposes a method to trim down an independent identically distributed training set
    while making two kinds of simple learners learn even better.
    They also provide a mixed-integer nonlinear programming-based algorithm for general learners.

    Machine teaching applications in cognitive psychology and education show potential impacts on the real world.
    \textcite{khan2011humans} 
















